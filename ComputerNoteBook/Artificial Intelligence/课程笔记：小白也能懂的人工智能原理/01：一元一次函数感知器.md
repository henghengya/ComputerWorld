---
title: 01：一元一次函数感知器
date: 2021-08-13 21:22:57
tags: 
  - Ronsenblatt感知器
  - Python
  - numpy
  - matplotlib
  - 人工智能
alias: 
category: 
stars: 
from: 
url: 
references: 
 - https://www.bilibili.com/cheese/play/ep6174
---
# 01：一元一次函数感知器：如何描述直觉

## 理论知识

人工智能要做的事情就是为问题找到一个函数用来描述它。

### 豆豆的毒性与大小之间的关系

假设有这样的一个生物小蓝，依靠吃豆豆生存。而豆豆本身具有毒性且只与豆豆大小有关，那么如何判断一个豆豆的毒性大小呢？

可以得出，豆豆大小与豆豆的毒性之间有一元一次函数的关系，豆豆大小是自变量，豆豆毒性是因变量。可用`y = w * x`表示，这里的w代表的就是大小与毒性之间的关系。

那么这个一元一次方函数就可以近似的看作生物的”直觉“。这是一个麦卡洛克-皮茨模型（McCullochPitts model），用来描述神经元中的树突与轴突的对应关系。每个树突传入的信号代表一个自变量，而轴突产生的结果代表因变量。最终会形成这样的多元一次函数：`y = w1 * x1 + w2 * x2 + ...`，这里的w代表的就是不同输入对输出的影响，即“权值”。

回到小蓝对豆豆的判断上来，那么如何找到w的值是多少呢？有个科学家提出了Rosenblatt感知器模型，使得神经元有了自己调节参数的能力。本着如无必要勿增新知的原则，依然用一元一次函数描述。

### Rosenblatt感知器模型

输入通过麦卡洛克-皮茨模型之后，输出一个结果，用“实际值-结果=误差”计算得误差，然后通过这个误差调整w。

例如通过w=w+误差，然后将新的w值重新计算。以此类推，这样就可以通过误差来调整w，当结果偏大时，误差为负。当结果偏小，误差为正。

而实际上Rosenblatt模型还需要乘自变量x，这是因为若输入的因变量是负数时，当结果偏大时，w应该增加而不是减少。而结果过小时应该减少而不是增加。

同时为了控制每一次调整的变化幅度，通常还会添加一个学习率参数。最终结果就是：
	`w = w + 误差 * x * 学习率α`

而Rosenblatt感知器模型之所以具有很高的地位，是因为它第一次从数学上完整的描述了一个神经元的运算过程，并且可以通过数学证明确定最终结果一定是收敛的，一定是归于一个值的。

## Python预备知识

```Python
import matplotlib.pyplot as plt  
import numpy as np  
  
  
# 产生豆豆的毒性和大小  
def get_beans(counts):  
    xa = np.random.rand(counts)  
 	xa = np.sort(xa)  
 	ya = [1.2 * x + np.random.rand() / 10 for x in xa]  
 	return xa, ya  
  
  
xa, ya = get_beans(100)  
  
# 画图  
plt.xlabel("Bean Size")  
plt.ylabel("Toxicity")  
# 绘制散点图  
plt.scatter(xa, ya)  
  
# y = 0.5 * x  
w = 0.5  
y_pre = w * xa  
# 绘制直线  
plt.plot(xa, y_pre)  
plt.show()  

```

## 编写Ronsenblatt感知器

```python
import time  
  
import matplotlib.pyplot as plt  
import numpy as np  
  
  
# 产生豆豆的毒性和大小  
def get_beans(counts):  
    xs__ = np.random.rand(counts)  
 	xs__ = np.sort(xs__)  
 	ys__ = [1.2 * x_ + np.random.rand() / 10 for x_ in xs__]  
 	return xs__, ys__  
  
  
# 画图  
def draw_init():  
	plt.xlabel("Bean Size")  
 	plt.ylabel("Toxicity")  
 	plt.title("Size-Toxicity Function")  
  
  
def draw(xs_, ys_, w_):  
    plt.clf() # 清理图像  
 	draw_init()  
 	plt.scatter(xs_, ys_)  
 	y_ = w_ * xs_  
    plt.plot(xs_, y_)  
 	plt.pause(0.000001) # 暂停  
  
  
number = 100  
xs, ys = get_beans(number)  
  
# y = w * x  
# 设置一个初始斜率  
w = 0.5  
# 一次完整的循环无法得到较准确的值，所以多来几次  
start = time.time()  
for m in range(10):  
    # 使用循环  
 	for i in range(number):  
        x = xs[i]  
 		y = ys[i]  
 		# 计算预测值  
 		y_pre = w * x  
        # 计算与真实情况的误差  
 		e = y - y_pre  
        # 学习率，防止直线斜率大幅变动  
 		alpha = 0.05  
 		# 通过一次学习改变斜率  
 		w = w + e * x * alpha  
        # 画出这一次的图像  
 		draw(xs, ys, w)  
  
end = time.time()  
print("运行时间：" + str(end-start) + "秒")
```